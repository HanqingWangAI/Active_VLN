{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from speaker import Speaker\n",
    "\n",
    "from utils import read_vocab,write_vocab,build_vocab,Tokenizer,padding_idx,timeSince, read_img_features, read_graph_features, read_graph_features_parallel\n",
    "import utils\n",
    "from env import R2RBatch\n",
    "from eval import Evaluation\n",
    "from param import args\n",
    "from agent import ActiveExplore_v1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "print('current directory',os.getcwd())\n",
    "os.chdir('..')\n",
    "print('current directory',os.getcwd())\n",
    "\n",
    "\n",
    "args.name = 'active'\n",
    "args.attn = 'soft'\n",
    "args.train = 'listener'\n",
    "args.featdropout = 0.3\n",
    "args.angle_feat_size = 128\n",
    "args.feedback = 'sample'\n",
    "args.ml_weight = 0.2\n",
    "args.sub_out = 'max'\n",
    "args.dropout = 0.5\n",
    "args.optim = 'adam'\n",
    "args.lr = 1e-4\n",
    "args.iters = 80000\n",
    "args.maxAction = 35\n",
    "args.batchSize = 64\n",
    "\n",
    "args.self_train = True\n",
    "args.aug = 'tasks/R2R/data/aug_paths.json'\n",
    "# args.aug = 'tasks/R2R/data/aug_paths_unseenvalid.json'\n",
    "args.speaker = 'snap/speaker/state_dict/best_val_unseen_bleu'\n",
    "\n",
    "args.featdropout = 0.4\n",
    "args.iters = 200000\n",
    "\n",
    "if args.optim == 'rms':\n",
    "    print(\"Optimizer: Using RMSProp\")\n",
    "    args.optimizer = torch.optim.RMSprop\n",
    "elif args.optim == 'adam':\n",
    "    print(\"Optimizer: Using Adam\")\n",
    "    args.optimizer = torch.optim.Adam\n",
    "elif args.optim == 'sgd':\n",
    "    print(\"Optimizer: sgd\")\n",
    "    args.optimizer = torch.optim.SGD\n",
    "elif args.optim == 'adabound':\n",
    "    print(\"Optimizer: adabound\")\n",
    "    args.optimizer = adabound.AdaBound\n",
    "\n",
    "\n",
    "\n",
    "log_dir = 'snap/%s' % args.name\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "TRAIN_VOCAB = 'tasks/R2R/data/train_vocab.txt'\n",
    "TRAINVAL_VOCAB = 'tasks/R2R/data/trainval_vocab.txt'\n",
    "\n",
    "IMAGENET_FEATURES = 'img_features/ResNet-152-imagenet.tsv'\n",
    "PLACE365_FEATURES = 'img_features/ResNet-152-places365.tsv'\n",
    "\n",
    "if args.features == 'imagenet':\n",
    "    features = IMAGENET_FEATURES\n",
    "\n",
    "if args.fast_train:\n",
    "    name, ext = os.path.splitext(features)\n",
    "    features = name + \"-fast\" + ext\n",
    "\n",
    "feedback_method = args.feedback # teacher or sample\n",
    "\n",
    "print(args)\n",
    "\n",
    "\n",
    "def setup():\n",
    "    torch.manual_seed(1)\n",
    "    torch.cuda.manual_seed(1)\n",
    "    # Check for vocabs\n",
    "    if not os.path.exists(TRAIN_VOCAB):\n",
    "        write_vocab(build_vocab(splits=['train']), TRAIN_VOCAB)\n",
    "    if not os.path.exists(TRAINVAL_VOCAB):\n",
    "        write_vocab(build_vocab(splits=['train','val_seen','val_unseen']), TRAINVAL_VOCAB)\n",
    "#\n",
    "setup()\n",
    "\n",
    "vocab = read_vocab(TRAIN_VOCAB)\n",
    "tok = Tokenizer(vocab=vocab, encoding_length=args.maxInput)\n",
    "\n",
    "feat_dict = read_img_features(features)\n",
    "\n",
    "print('start extract keys...')\n",
    "featurized_scans = set([key.split(\"_\")[0] for key in list(feat_dict.keys())])\n",
    "print('keys extracted...')\n",
    "\n",
    "# Load the augmentation data\n",
    "aug_path = args.aug\n",
    "\n",
    "# Create the training environment\n",
    "train_env = R2RBatch(feat_dict, batch_size=args.batchSize,\n",
    "                     splits=['train'], tokenizer=tok)\n",
    "aug_env   = R2RBatch(feat_dict, batch_size=args.batchSize,\n",
    "                     splits=[aug_path], tokenizer=tok, name='aug')\n",
    "aug_unseen_env   = R2RBatch(feat_dict, batch_size=args.batchSize,\n",
    "                     splits=['tasks/R2R/data/aug_paths_unseenvalid.json'], tokenizer=tok, name='aug')\n",
    "\n",
    "# Printing out the statistics of the dataset\n",
    "stats = train_env.get_statistics()\n",
    "print(\"The training data_size is : %d\" % train_env.size())\n",
    "print(\"The average instruction length of the dataset is %0.4f.\" % (stats['length']))\n",
    "print(\"The average action length of the dataset is %0.4f.\" % (stats['path']))\n",
    "# stats = aug_env.get_statistics()\n",
    "# print(\"The augmentation data size is %d\" % aug_env.size())\n",
    "# print(\"The average instruction length of the dataset is %0.4f.\" % (stats['length']))\n",
    "# print(\"The average action length of the dataset is %0.4f.\" % (stats['path']))\n",
    "\n",
    "# Setup the validation data\n",
    "val_envs = {split: (R2RBatch(feat_dict, batch_size=args.batchSize, splits=[split],\n",
    "                             tokenizer=tok), Evaluation([split], featurized_scans, tok))\n",
    "            for split in ['train', 'val_seen', 'val_unseen']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "import traceback\n",
    "\n",
    "\n",
    "args.load = 'snap/agent/state_dict/best_val_unseen'\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "def test(train_env, tok, n_iters, log_every=100, val_envs={}, aug_env=None):\n",
    "    writer = SummaryWriter(logdir=log_dir)\n",
    "    \n",
    "    listner = ActiveExplore_v1(train_env, \"\", tok, episode_len=args.maxAction)\n",
    "    \n",
    "    speaker = None\n",
    "    if args.self_train:\n",
    "        speaker = Speaker(train_env, listner, tok)\n",
    "        if args.speaker is not None:\n",
    "            print(\"Load the speaker from %s.\" % args.speaker)\n",
    "            speaker.load(args.speaker)\n",
    "\n",
    "    start_iter = 0\n",
    "    if args.load is not None:\n",
    "        print(\"LOAD THE listener from %s\" % args.load)\n",
    "        start_iter = listner.load(os.path.join(args.load))\n",
    "        start_iter = 0\n",
    "        \n",
    "    ths = np.ones([args.maxAction])*3\n",
    "    ths[0] = 0.456\n",
    "    ths[1] = 0.485\n",
    "    ths[2] = 0.493\n",
    "    ths[3] = 0.584\n",
    "    ths[4] = 0.574\n",
    "    ths[5] = 0.418\n",
    "    ths[6] = 0.675\n",
    "        \n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    best_val = {'val_seen': {\"accu\": 0., \"state\":\"\", 'update':False},\n",
    "                'val_unseen': {\"accu\": 0., \"state\":\"\", 'update':False}}\n",
    "    if args.fast_train:\n",
    "        log_every = 40\n",
    "    try:\n",
    "        loss_str = \"\"\n",
    "        for env_name, (env, evaluator) in val_envs.items():\n",
    "            listner.env = env\n",
    "            listner.logs = defaultdict(list)\n",
    "\n",
    "            # Get validation loss under the same conditions as training\n",
    "            iters = None if args.fast_train or env_name != 'train' else 20     # 20 * 64 = 1280\n",
    "#             iters = 5\n",
    "\n",
    "            # Get validation distance from goal under test evaluation conditions\n",
    "            listner.test(use_dropout=False, feedback='argmax', iters=iters, train_exp=True, ths=ths)\n",
    "            result = listner.get_results()\n",
    "            score_summary, score_details = evaluator.score(result)\n",
    "\n",
    "\n",
    "            with open('traj.json','w') as fp:\n",
    "                json.dump(result,fp,indent=4)\n",
    "\n",
    "\n",
    "            loss_str += \", %s \\n\" % env_name\n",
    "     \n",
    "            for metric,val in score_summary.items():\n",
    "                loss_str += ', %s: %.3f' % (metric, val)\n",
    "            loss_str += '\\n'\n",
    "\n",
    "\n",
    "            print(loss_str)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        del listner\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "test(train_env, tok, args.iters,log_every=20, val_envs=val_envs, aug_env=[aug_env,aug_unseen_env])\n",
    "# listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:naacl] *",
   "language": "python",
   "name": "conda-env-naacl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
